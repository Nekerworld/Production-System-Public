# ìˆ˜ë™ ê²€ì‚¬ í˜ì´ì§€
# ì‚¬ìš©ìê°€ ì§ì ‘ ì „ë¥˜ì™€ ì˜¨ë„ ê°’ì„ ì…ë ¥í•˜ì—¬ ê²€ì‚¬
# ì…ë ¥ëœ ë°ì´í„°ì— ëŒ€í•œ ì •ìƒ/ì´ìƒ í™•ë¥  ê³„ì‚°
# ì…ë ¥ ë°ì´í„°ì˜ ì‹œê°í™”
# ê²€ì‚¬ ê²°ê³¼ íˆìŠ¤í† ë¦¬

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import logging
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler
import joblib
from typing import List, Tuple, Optional, Dict, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜
SEQ_LEN = 10  # ì‹œí€€ìŠ¤ ê¸¸ì´

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìˆ˜ë™ ê²€ì‚¬",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AnomalyPredictor:
    """ì´ìƒì¹˜ ì˜ˆì¸¡ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, model_dir: str = 'models'):
        """
        Args:
            model_dir (str): ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.model_dir = model_dir
        self.model = None
        self.scalers = []
        self.seq_len = SEQ_LEN  # ì‹œí€€ìŠ¤ ê¸¸ì´
        self.threshold = 0.5  # ì´ìƒì¹˜ íŒë‹¨ ì„ê³„ê°’
        
    def load_models(self) -> None:
        """ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # ëª¨ë¸ ë¡œë“œ
            model_path = os.path.join(self.model_dir, 'prediction_model.h5')
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            self.model = load_model(model_path)
            logger.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            scaler_files = [f for f in os.listdir(self.model_dir) if f.endswith('_scaler.pkl')]
            if not scaler_files:
                raise FileNotFoundError("ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            self.scalers = []
            for scaler_file in scaler_files:
                scaler_path = os.path.join(self.model_dir, scaler_file)
                scaler = joblib.load(scaler_path)
                self.scalers.append(scaler)
            logger.info(f"{len(self.scalers)}ê°œì˜ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def prepare_sequence(self, data: pd.DataFrame, scaler: StandardScaler) -> np.ndarray:
        """
        ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì…ë ¥ ë°ì´í„°
            scaler (StandardScaler): ìŠ¤ì¼€ì¼ëŸ¬ ê°ì²´
            
        Returns:
            np.ndarray: ì‹œí€€ìŠ¤ ë°ì´í„°
        """
        try:
            if len(data) < self.seq_len:
                raise ValueError(f"ë°ì´í„° ê¸¸ì´ê°€ {self.seq_len}ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.")
            
            # feature ì´ë¦„ì´ ìˆëŠ” DataFrameìœ¼ë¡œ ë³€í™˜
            features = pd.DataFrame(data[['Temp', 'Current']], columns=['Temp', 'Current'])
            
            # ìŠ¤ì¼€ì¼ë§ (DataFrame í˜•íƒœ ìœ ì§€)
            scaled_data = pd.DataFrame(
                scaler.transform(features),
                columns=features.columns,
                index=features.index
            )
            
            # ì‹œí€€ìŠ¤ ìƒì„±
            X = []
            for i in range(len(data) - self.seq_len + 1):
                X.append(scaled_data.iloc[i:i+self.seq_len].values)
            return np.array(X)
            
        except Exception as e:
            logger.error(f"ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def format_prediction_result(self, 
                               predictions: np.ndarray, 
                               data: pd.DataFrame,
                               last_probability: float) -> Dict[str, Any]:
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        Args:
            predictions (np.ndarray): ì˜ˆì¸¡ í™•ë¥  ë°°ì—´
            data (pd.DataFrame): ì›ë³¸ ë°ì´í„°
            last_probability (float): ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ 
            
        Returns:
            Dict[str, Any]: í¬ë§·íŒ…ëœ ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ë°ì´í„° ì¶”ì¶œ
            last_sequence = data.iloc[-self.seq_len:]
            
            # datetime ì²˜ë¦¬
            start_time = last_sequence['datetime'].iloc[0]
            end_time = last_sequence['datetime'].iloc[-1]
            
            # datetimeì´ ë¬¸ìì—´ì¸ ê²½ìš° datetime ê°ì²´ë¡œ ë³€í™˜
            if isinstance(start_time, str):
                start_time = pd.to_datetime(start_time)
            if isinstance(end_time, str):
                end_time = pd.to_datetime(end_time)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            timestamps = data['datetime'].iloc[-len(predictions):]
            if isinstance(timestamps.iloc[0], str):
                timestamps = pd.to_datetime(timestamps)
            
            # Plotly ì°¨íŠ¸ ìƒì„±
            fig = make_subplots(rows=2, cols=1,
                              shared_xaxes=True,
                              vertical_spacing=0.05,
                              subplot_titles=('Temperature', 'Current'))
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=data['Temp'].iloc[-len(predictions):],
                          name='Temperature', line=dict(color='blue')),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=data['Current'].iloc[-len(predictions):],
                          name='Current', line=dict(color='green')),
                row=2, col=1
            )
            
            fig.update_layout(
                height=600,
                showlegend=True,
                title_text="Sensor Data with Predictions"
            )
            
            result = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'anomaly_probability': float(last_probability),
                'is_anomaly': bool(last_probability >= self.threshold),
                'last_sequence': {
                    'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'end_time': end_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'avg_temperature': float(last_sequence['Temp'].mean()),
                    'avg_current': float(last_sequence['Current'].mean()),
                    'process_id': int(last_sequence['Process'].iloc[-1])
                },
                'prediction_history': {
                    'timestamps': [ts.strftime('%Y-%m-%d %H:%M:%S') for ts in timestamps],
                    'probabilities': [float(p[0]) for p in predictions]
                },
                'visualization': fig
            }
            
            return result
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {str(e)}")
            raise
    
    def predict(self, data: pd.DataFrame) -> Tuple[np.ndarray, float, Dict[str, Any]]:
        """
        ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì´ìƒì¹˜ í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì˜ˆì¸¡í•  ë°ì´í„°
            
        Returns:
            Tuple[np.ndarray, float, Dict[str, Any]]: 
                (ì „ì²´ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ , ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ , í¬ë§·íŒ…ëœ ê²°ê³¼)
        """
        try:
            if self.model is None or not self.scalers:
                self.load_models()
            
            # datetime ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìƒì„±
            if 'datetime' not in data.columns:
                data['Time'] = (data['Time'].str.replace('ì˜¤ì „', 'AM')
                                          .str.replace('ì˜¤í›„', 'PM'))
                data['Time'] = pd.to_datetime(data['Time'], format='%p %I:%M:%S.%f').dt.strftime('%H:%M:%S.%f')
                data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])
            
            all_predictions = []
            
            # ê° ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
            for scaler in self.scalers:
                X = self.prepare_sequence(data, scaler)
                predictions = self.model.predict(X, verbose=0)
                all_predictions.append(predictions)
            
            # ëª¨ë“  ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ í†µí•œ ì˜ˆì¸¡ í‰ê· 
            final_predictions = np.mean(all_predictions, axis=0)
            
            # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ 
            last_probability = final_predictions[-1][0]
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_result = self.format_prediction_result(final_predictions, data, last_probability)
            
            logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì´ìƒì¹˜ í™•ë¥  = {last_probability*100:.2f}%")
            return final_predictions, last_probability, formatted_result
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            raise

    def predict_anomaly_probability(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ë°ì´í„°ì˜ ì´ìƒì¹˜ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ë¶„ì„í•  ë°ì´í„°
            
        Returns:
            Dict[str, Any]: ì´ìƒì¹˜ í™•ë¥ ê³¼ ê´€ë ¨ ì •ë³´
        """
        try:
            # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ë¡œë“œ
            if self.model is None or not self.scalers:
                self.load_models()
            
            # datetime ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìƒì„±
            if 'datetime' not in data.columns:
                data['Time'] = (data['Time'].str.replace('ì˜¤ì „', 'AM')
                                          .str.replace('ì˜¤í›„', 'PM'))
                data['Time'] = pd.to_datetime(data['Time'], format='%p %I:%M:%S.%f').dt.strftime('%H:%M:%S.%f')
                data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])
            
            # ê° ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
            all_predictions = []
            for scaler in self.scalers:
                X = self.prepare_sequence(data, scaler)
                predictions = self.model.predict(X, verbose=0)
                all_predictions.append(predictions)
            
            # ëª¨ë“  ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ í†µí•œ ì˜ˆì¸¡ í‰ê· 
            final_predictions = np.mean(all_predictions, axis=0)
            
            # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ 
            last_probability = float(final_predictions[-1][0])
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'anomaly_probability': last_probability,
                'anomaly_percentage': last_probability * 100,
                'is_anomaly': bool(last_probability >= self.threshold),
                'threshold': float(self.threshold),
                'confidence_level': 'ë†’ìŒ' if last_probability > 0.8 else 'ì¤‘ê°„' if last_probability > 0.5 else 'ë‚®ìŒ',
                'data_summary': {
                    'total_points': len(data),
                    'sequence_length': self.seq_len,
                    'last_sequence': {
                        'start_time': data['datetime'].iloc[-self.seq_len].strftime('%Y-%m-%d %H:%M:%S'),
                        'end_time': data['datetime'].iloc[-1].strftime('%Y-%m-%d %H:%M:%S'),
                        'avg_temperature': float(data['Temp'].iloc[-self.seq_len:].mean()),
                        'avg_current': float(data['Current'].iloc[-self.seq_len:].mean())
                    }
                },
                'predictions': final_predictions.tolist(),  # ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼
                'last_prediction': last_probability  # ë§ˆì§€ë§‰ ì˜ˆì¸¡ê°’ ì¶”ê°€
            }
            
            logger.info(f"ì´ìƒì¹˜ í™•ë¥  ê³„ì‚° ì™„ë£Œ: {result['anomaly_percentage']:.2f}%")
            return result
            
        except Exception as e:
            logger.error(f"ì´ìƒì¹˜ í™•ë¥  ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            raise

@st.cache_resource
def get_predictor():
    """AnomalyPredictor ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìºì‹±í•˜ì—¬ ëª¨ë¸ ë¡œë“œë¥¼ í•œ ë²ˆë§Œ ìˆ˜í–‰"""
    predictor = AnomalyPredictor()
    try:
        predictor.load_models()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}. 'models' ë””ë ‰í† ë¦¬ì— prediction_model.h5ì™€ scaler íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    return predictor

def main():
    st.title("ìˆ˜ë™ ê²€ì‚¬ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---<")

    predictor = get_predictor()
    if predictor is None:
        return

    st.subheader("ìƒˆë¡œìš´ ë°ì´í„° ì…ë ¥")
    col1, col2 = st.columns(2)

    with col1:
        current_input = st.number_input("ì „ë¥˜ ê°’ (Current)", min_value=0.0, value=1.0, step=0.01)
    with col2:
        temp_input = st.number_input("ì˜¨ë„ ê°’ (Temperature)", min_value=0.0, value=25.0, step=0.01)

    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ìœ¼ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•œ ê°€ìƒì˜ ê³¼ê±° ë°ì´í„° (SEQ_LEN - 1ê°œ)
    # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì—°ì†ì ì¸ ì„¼ì„œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ìœ„í•´ ì„ì‹œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    if 'manual_check_data_history' not in st.session_state:
        st.session_state.manual_check_data_history = pd.DataFrame(columns=['Date', 'Time', 'Current', 'Temp', 'Process', 'datetime'])
    
    if st.button("ì´ìƒì¹˜ ê²€ì‚¬ ì‹¤í–‰"):
        if len(st.session_state.manual_check_data_history) < (SEQ_LEN - 1):
            st.warning(f"ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {SEQ_LEN-1}ê°œì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.info(f"í˜„ì¬ {len(st.session_state.manual_check_data_history)}ê°œ ë°ì´í„°ë§Œ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ë²ˆ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ë¶€ì¡±í•œ ë°ì´í„°ë¥¼ ì„ì‹œë¡œ ì±„ì›Œ ë„£ê¸° (ì´ˆê¸° ì‹¤í–‰ ì‹œ)
            for _ in range((SEQ_LEN - 1) - len(st.session_state.manual_check_data_history)):
                dummy_time = datetime.now() - timedelta(seconds=(SEQ_LEN - 1 - _))
                st.session_state.manual_check_data_history = pd.concat([st.session_state.manual_check_data_history, pd.DataFrame({
                    'Date': [dummy_time.strftime('%Y-%m-%d')],
                    'Time': [dummy_time.strftime('%p %I:%M:%S.%f')],
                    'Current': [1.0], 
                    'Temp': [25.0], 
                    'Process': [1],
                    'datetime': [dummy_time]
                })], ignore_index=True)

        # ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ ìƒì„±
        current_time = datetime.now()
        new_data_point = pd.DataFrame({
            'Date': [current_time.strftime('%Y-%m-%d')],
            'Time': [current_time.strftime('%p %I:%M:%S.%f')],
            'Current': [current_input], 
            'Temp': [temp_input], 
            'Process': [1], # ì˜ˆì‹œ í”„ë¡œì„¸ìŠ¤ ID
            'datetime': [current_time]
        })
        
        # í˜„ì¬ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ê°€
        st.session_state.manual_check_data_history = pd.concat([st.session_state.manual_check_data_history, new_data_point], ignore_index=True)
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ë§Œ ìœ ì§€ (ì˜ˆì¸¡ì— í•„ìš”í•œ ìµœì†Œ ê¸¸ì´)
        if len(st.session_state.manual_check_data_history) > SEQ_LEN:
            st.session_state.manual_check_data_history = st.session_state.manual_check_data_history.tail(SEQ_LEN).reset_index(drop=True)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        try:
            # ì˜ˆì¸¡ ëª¨ë“ˆì€ SEQ_LEN ê¸¸ì´ì˜ ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.
            # ë”°ë¼ì„œ historyì—ì„œ SEQ_LEN ë§Œí¼ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            if len(st.session_state.manual_check_data_history) < SEQ_LEN:
                st.error(f"ë°ì´í„° ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë¶€ì¡±í•˜ì—¬ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {SEQ_LEN}ê°œì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                st.stop() # ì˜ˆì¸¡ ì¤‘ì§€

            data_for_prediction = st.session_state.manual_check_data_history.tail(SEQ_LEN).copy()
            # PredictionModuleì—ì„œ predict_anomaly_probability í•¨ìˆ˜ëŠ” predictì™€ ë³„ê°œë¡œ ì¡´ì¬í–ˆìœ¼ë¯€ë¡œ,
            # ì—¬ê¸°ì„œëŠ” predict í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ê°’ì„ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
            _, last_prob, result = predictor.predict(data_for_prediction)
            
            # format_prediction_resultì—ì„œ anomaly_percentageê°€ ì§ì ‘ ê³„ì‚°ë˜ì–´ ë“¤ì–´ì˜¤ë¯€ë¡œ ì´ ë¶€ë¶„ì„ ìˆ˜ì •
            result['anomaly_percentage'] = last_prob * 100
            result['threshold'] = predictor.threshold # AnomalyPredictor í´ë˜ìŠ¤ ë‚´ì˜ threshold ì‚¬ìš©
            result['confidence_level'] = 'ë†’ìŒ' if last_prob > 0.8 else 'ì¤‘ê°„' if last_prob > 0.5 else 'ë‚®ìŒ'
            

            # ê²°ê³¼ í‘œì‹œ
            st.subheader("ê²€ì‚¬ ê²°ê³¼")
            col_res1, col_res2 = st.columns(2)
            with col_res1:
                st.metric("ì´ìƒì¹˜ í™•ë¥ ", f"{result['anomaly_percentage']:.2f}%")
            with col2:
                status_text = "ì •ìƒ" if not result['is_anomaly'] else "ì´ìƒ ê°ì§€"
                status_color = "green" if not result['is_anomaly'] else "red"
                st.markdown(f"<div style='font-size:20px; color:{status_color}; font-weight:bold;'>ìƒíƒœ: {status_text}</div>", unsafe_allow_html=True)
            
            st.info(f"**ì„ê³„ê°’:** {result['threshold']:.2f}, **ì‹ ë¢°ë„:** {result['confidence_level']}")

            # ì…ë ¥ ë°ì´í„° ì‹œê°í™”
            st.subheader("ì…ë ¥ ë°ì´í„° ì‹œê°í™”")
            st.plotly_chart(result['visualization'], use_container_width=True)
            
            # ê²€ì‚¬ ê²°ê³¼ íˆìŠ¤í† ë¦¬ ì €ì¥ ë° í‘œì‹œ
            if 'manual_check_history' not in st.session_state:
                st.session_state.manual_check_history = []
            
            st.session_state.manual_check_history.append({
                'timestamp': current_time.strftime('%Y-%m-%d %H:%M:%S'),
                'current': current_input,
                'temperature': temp_input,
                'probability': result['anomaly_percentage'],
                'status': status_text
            })
            
            st.subheader("ê²€ì‚¬ ê²°ê³¼ íˆìŠ¤í† ë¦¬")
            # ìµœì‹  10ê°œë§Œ í‘œì‹œ
            display_history = pd.DataFrame(st.session_state.manual_check_history).tail(10)
            if not display_history.empty:
                st.dataframe(display_history.set_index('timestamp'))
            else:
                st.info("ì•„ì§ ê²€ì‚¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except ValueError as ve:
            st.error(f"ë°ì´í„° ì˜¤ë¥˜: {ve}")
            st.warning("ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 10ê°œì˜ ì—°ì†ëœ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. ëª‡ ë²ˆ ë” ì…ë ¥í•´ë³´ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.markdown("---<")
    st.markdown("**ì°¸ê³ :** ì˜ˆì¸¡ ëª¨ë¸ì€ ìµœì†Œ 10ê°œì˜ ì—°ì†ëœ ë°ì´í„° í¬ì¸íŠ¸(ì‹œí€€ìŠ¤)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ì²« ëª‡ ë²ˆì˜ ì…ë ¥ ì‹œì—ëŠ” 'ê³¼ê±° ë°ì´í„° ë¶€ì¡±' ë©”ì‹œì§€ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
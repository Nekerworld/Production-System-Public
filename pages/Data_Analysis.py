# ë°ì´í„° ë¶„ì„ íŽ˜ì´ì§€
# ê³¼ê±° ë°ì´í„° ë¶„ì„
# ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„
# ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ
# ë°ì´í„° í†µê³„ ì •ë³´

# 3ë²ˆíŒŒì¼ì€ Alert Settings ì˜€ëŠ”ë°, ê°œë°œ ë„ì¤‘ ì‚­ì œí•˜ê³  Settingsë¡œ í†µí•©í•˜ì˜€ìŠµë‹ˆë‹¤.

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
from pathlib import Path
from glob import glob

# íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë°ì´í„° ë¶„ì„",
    page_icon="ðŸ“Š",
    layout="wide"
)

@st.cache_data # ë°ì´í„°ë¥¼ ìºì‹±í•˜ì—¬ ìž¬ë¡œë“œ ë°©ì§€
def load_historical_data():
    """ê³¼ê±° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ê²½ë¡œ ì„¤ì • (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        DATA_DIR = os.path.join('data', 'ìž¥ë¹„ì´ìƒ ì¡°ê¸°íƒì§€', '5ê³µì •_180sec')
        csv_paths = [p for p in glob(os.path.join(DATA_DIR, '*.csv')) if
                    'Error Lot list' not in os.path.basename(p)]
        
        if not csv_paths:
            st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì—ëŸ¬ ë°ì´í„° ë¡œë“œ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        error_df = pd.read_csv(os.path.join(DATA_DIR, 'Error Lot list.csv'))
        
        # mark_anomaly í•¨ìˆ˜ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        def mark_anomaly(df, err):
            df['is_anomaly'] = 0
            for _, row in err.iterrows():
                date = str(row.iloc[0]).strip()
                procs = set(row.iloc[1:].dropna().astype(int))
                if procs:
                    mask = (df['Date'] == date) & (df['Process'].isin(procs))
                    df.loc[mask, 'is_anomaly'] = 1
            return df
        
        # load_one í•¨ìˆ˜ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        def load_one(path):
            df = pd.read_csv(path)
            df['Time'] = (df['Time'].str.replace('ì˜¤ì „', 'AM')
                                  .str.replace('ì˜¤í›„', 'PM'))
            df['Time'] = pd.to_datetime(df['Time'], format='%p %I:%M:%S.%f').dt.strftime('%H:%M:%S.%f')
            df['timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])
            df['Index'] = df['Index'].astype(int)
            df = mark_anomaly(df, error_df)

            # --- ë°ëª¨ë¥¼ ìœ„í•œ ë”ë¯¸ 'prediction' ì»¬ëŸ¼ ì¶”ê°€ ---
            np.random.seed(42)
            df['prediction'] = np.zeros(len(df))
            df.loc[df['is_anomaly'] == 1, 'prediction'] = np.random.uniform(0.6, 0.9, size=df['is_anomaly'].sum())
            df.loc[df['is_anomaly'] == 0, 'prediction'] = np.random.uniform(0.1, 0.4, size=(len(df) - df['is_anomaly'].sum()))
            # --- ë”ë¯¸ 'prediction' ì»¬ëŸ¼ ì¶”ê°€ ë ---

            return df
        
        # ëª¨ë“  ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
        dataframes = [load_one(p) for p in csv_paths]
        df = pd.concat(dataframes, ignore_index=True)
        
        return df
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ì „ì—­ íŒŒë¼ë¯¸í„° (ì´ íŽ˜ì´ì§€ì˜ ë¶„ì„ ë¡œì§ì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.)
WINDOW_WIDTH  = 3    
SLIDE_STEP    = 1    
SEQ_LEN       = 10   
TRAIN_RATIO   = 0.7
VAL_RATIO     = 0.1

def analyze_anomaly_patterns(df):
    """ì´ìƒ ê°ì§€ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    if df is None or 'is_anomaly' not in df.columns:
        return None
    
    anomaly_df = df[df['is_anomaly'] == 1]
    
    # ì‹œê°„ëŒ€ë³„ ì´ìƒ ë°œìƒ ë¹ˆë„
    anomaly_df['hour'] = pd.to_datetime(anomaly_df['timestamp']).dt.hour
    hourly_pattern = anomaly_df.groupby('hour').size()
    
    # ì´ìƒì¹˜ ë°œìƒ ê°„ê²© ë¶„ì„
    anomaly_df['timestamp'] = pd.to_datetime(anomaly_df['timestamp'])
    anomaly_df = anomaly_df.sort_values('timestamp')
    anomaly_df['time_diff'] = anomaly_df['timestamp'].diff()
    
    return {
        'hourly_pattern': hourly_pattern,
        'time_diff': anomaly_df['time_diff']
    }

def calculate_model_metrics(df):
    """ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    if df is None or 'is_anomaly' not in df.columns or 'prediction' not in df.columns:
        return None
    
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    # ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ì´ì§„ í´ëž˜ìŠ¤ë¡œ ë³€í™˜ (ìž„ê³„ê°’ 0.5 ì‚¬ìš© ì˜ˆì‹œ)
    # ì‹¤ì œ ëª¨ë¸ì—ì„œëŠ” ì´ ìž„ê³„ê°’ì„ ì¡°ì •í•´ì•¼ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
    binary_prediction = (df['prediction'] >= 0.5).astype(int)

    metrics = {
        'precision': precision_score(df['is_anomaly'], binary_prediction),
        'recall': recall_score(df['is_anomaly'], binary_prediction),
        'f1': f1_score(df['is_anomaly'], binary_prediction)
    }
    
    return metrics

def get_total_data_points():
    """ì „ì²´ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    df = load_historical_data()
    if df is None:
        return 0
    return len(df)

def main():
    st.title("ðŸ“Š ë°ì´í„° ë¶„ì„")
    
    # ë°ì´í„° ë¡œë“œ
    df = load_historical_data()
    
    if df is None: # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ
        return
    
    # 1. ë°ì´í„° í†µê³„ ì •ë³´
    st.header("ë°ì´í„° í†µê³„ ì •ë³´")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë°ì´í„° í¬ì¸íŠ¸", len(df))
    with col2:
        # 'is_anomaly' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
        if 'is_anomaly' in df.columns:
            st.metric("ì´ìƒì¹˜ ìˆ˜", int(df['is_anomaly'].sum()))
        else:
            st.metric("ì´ìƒì¹˜ ìˆ˜", "N/A")
    with col3:
        if 'is_anomaly' in df.columns:
            st.metric("ì •ìƒ ë°ì´í„° ìˆ˜", int(len(df) - df['is_anomaly'].sum()))
        else:
            st.metric("ì •ìƒ ë°ì´í„° ìˆ˜", "N/A")
    
    # 2. ê³¼ê±° ë°ì´í„° ë¶„ì„
    st.header("ê³¼ê±° ë°ì´í„° ë¶„ì„")
    
    # 'timestamp', 'current', 'temperature' ì»¬ëŸ¼ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
    if 'timestamp' in df.columns and 'current' in df.columns and 'temperature' in df.columns:
        # ì‹œê°„ ë²”ìœ„ ì„ íƒ
        # dfì˜ ìµœì†Œ/ìµœëŒ€ timestampë¥¼ ê¸°ë°˜ìœ¼ë¡œ default value ì„¤ì •
        min_date = df['timestamp'].min().date()
        max_date = df['timestamp'].max().date()
        
        date_range = st.date_input(
            "ë¶„ì„í•  ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date
        )
        
        if len(date_range) == 2:
            start_date, end_date = date_range
            mask = (df['timestamp'] >= pd.Timestamp(start_date)) & (df['timestamp'] <= pd.Timestamp(end_date))
            filtered_df = df[mask]
            
            if not filtered_df.empty:
                # ì‹œê³„ì—´ ê·¸ëž˜í”„
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=filtered_df['timestamp'],
                    y=filtered_df['current'],
                    name='ì „ë¥˜',
                    line=dict(color='blue')
                ))
                fig.add_trace(go.Scatter(
                    x=filtered_df['timestamp'],
                    y=filtered_df['temperature'],
                    name='ì˜¨ë„',
                    line=dict(color='red'),
                    yaxis='y2'
                ))
                
                # ì´ìƒì¹˜ ë§ˆí‚¹
                anomaly_points = filtered_df[filtered_df['is_anomaly'] == 1]
                if not anomaly_points.empty:
                    fig.add_trace(go.Scatter(
                        x=anomaly_points['timestamp'],
                        y=anomaly_points['current'],
                        mode='markers',
                        marker=dict(color='red', size=8, symbol='x'),
                        name='ì´ìƒì¹˜ (ì „ë¥˜)'
                    ))
                    fig.add_trace(go.Scatter(
                        x=anomaly_points['timestamp'],
                        y=anomaly_points['temperature'],
                        mode='markers',
                        marker=dict(color='red', size=8, symbol='x'),
                        name='ì´ìƒì¹˜ (ì˜¨ë„)',
                        yaxis='y2'
                    ))
                
                fig.update_layout(
                    title='ì „ë¥˜ ë° ì˜¨ë„ ì‹œê³„ì—´ ë°ì´í„°',
                    xaxis_title='ì‹œê°„',
                    yaxis_title='ì „ë¥˜ (A)',
                    yaxis2=dict(
                        title='ì˜¨ë„ (Â°C)',
                        overlaying='y',
                        side='right'
                    ),
                    hovermode='x unified'
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ì„ íƒëœ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ê³¼ê±° ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ (timestamp, current, temperature)ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # 3. ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„
    st.header("ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„")
    
    if 'is_anomaly' in df.columns and 'timestamp' in df.columns:
        pattern_analysis = analyze_anomaly_patterns(df)
        if pattern_analysis:
            col1, col2 = st.columns(2)
            
            with col1:
                # ì‹œê°„ëŒ€ë³„ ì´ìƒ ë°œìƒ ë¹ˆë„
                fig = px.bar(
                    x=pattern_analysis['hourly_pattern'].index,
                    y=pattern_analysis['hourly_pattern'].values,
                    title='ì‹œê°„ëŒ€ë³„ ì´ìƒ ë°œìƒ ë¹ˆë„',
                    labels={'x': 'ì‹œê°„', 'y': 'ì´ìƒ ë°œìƒ íšŸìˆ˜'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # ì´ìƒì¹˜ ë°œìƒ ê°„ê²© ížˆìŠ¤í† ê·¸ëž¨
                # timedeltaë¥¼ ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜
                time_diff_minutes = pattern_analysis['time_diff'].dt.total_seconds() / 60
                fig = px.histogram(
                    time_diff_minutes,
                    title='ì´ìƒì¹˜ ë°œìƒ ê°„ê²© ë¶„í¬ (ë¶„)',
                    labels={'value': 'ê°„ê²© (ë¶„)', 'count': 'ë¹ˆë„'}
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì´ìƒ ê°ì§€ íŒ¨í„´ì„ ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ (is_anomaly, timestamp)ì´ ì—†ìŠµë‹ˆë‹¤.")

    
    # 4. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ
    st.header("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
    
    if 'is_anomaly' in df.columns and 'prediction' in df.columns:
        metrics = calculate_model_metrics(df)
        if metrics:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì •ë°€ë„ (Precision)", f"{metrics['precision']:.3f}")
            with col2:
                st.metric("ìž¬í˜„ìœ¨ (Recall)", f"{metrics['recall']:.3f}")
            with col3:
                st.metric("F1 ì ìˆ˜", f"{metrics['f1']:.3f}")
            
            # ROC ì»¤ë¸Œ
            from sklearn.metrics import roc_curve, auc
            fpr, tpr, _ = roc_curve(df['is_anomaly'], df['prediction'])
            roc_auc = auc(fpr, tpr)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=fpr,
                y=tpr,
                name=f'ROC ì»¤ë¸Œ (AUC = {roc_auc:.3f})'
            ))
            fig.add_trace(go.Scatter(
                x=[0, 1],
                y=[0, 1],
                name='ë¬´ìž‘ìœ„ ì˜ˆì¸¡',
                line=dict(dash='dash')
            ))
            
            fig.update_layout(
                title='ROC ì»¤ë¸Œ',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                xaxis=dict(range=[0, 1], constrain='range'), # ROC ì»¤ë¸Œ ë²”ìœ„ ê³ ì •
                yaxis=dict(range=[0, 1], scaleanchor='x', scaleratio=1, constrain='range') # ROC ì»¤ë¸Œ ë²”ìœ„ ê³ ì •
            )
            
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ (is_anomaly, prediction)ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
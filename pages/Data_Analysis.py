# ë°ì´í„° ë¶„ì„ í˜ì´ì§€
# ê³¼ê±° ë°ì´í„° ë¶„ì„
# ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„
# ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ
# ë°ì´í„° í†µê³„ ì •ë³´

# 3ë²ˆíŒŒì¼ì€ Alert Settings ì˜€ëŠ”ë°, ê°œë°œ ë„ì¤‘ ì‚­ì œí•˜ê³  Settingsë¡œ í†µí•©í•˜ì˜€ìŠµë‹ˆë‹¤.

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
from pathlib import Path
from glob import glob

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë°ì´í„° ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide"
)

@st.cache_data # ë°ì´í„°ë¥¼ ìºì‹±í•˜ì—¬ ì¬ë¡œë“œ ë°©ì§€
def load_historical_data():
    """ê³¼ê±° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ê²½ë¡œ ì„¤ì • (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        DATA_DIR = os.path.join('data', 'ì¥ë¹„ì´ìƒ ì¡°ê¸°íƒì§€', '5ê³µì •_180sec')
        csv_paths = [p for p in glob(os.path.join(DATA_DIR, '*.csv')) if
                    'Error Lot list' not in os.path.basename(p)]
        
        if not csv_paths:
            st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì—ëŸ¬ ë°ì´í„° ë¡œë“œ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        error_df = pd.read_csv(os.path.join(DATA_DIR, 'Error Lot list.csv'))
        
        # mark_anomaly í•¨ìˆ˜ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        def mark_anomaly(df, err):
            df['is_anomaly'] = 0
            for _, row in err.iterrows():
                date = str(row.iloc[0]).strip()
                procs = set(row.iloc[1:].dropna().astype(int))
                if procs:
                    mask = (df['Date'] == date) & (df['Process'].isin(procs))
                    df.loc[mask, 'is_anomaly'] = 1
            return df
        
        # load_one í•¨ìˆ˜ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ì˜)
        def load_one(path):
            df = pd.read_csv(path)
            df['Time'] = (df['Time'].str.replace('ì˜¤ì „', 'AM')
                                  .str.replace('ì˜¤í›„', 'PM'))
            df['Time'] = pd.to_datetime(df['Time'], format='%p %I:%M:%S.%f').dt.strftime('%H:%M:%S.%f')
            df['timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])
            df['Index'] = df['Index'].astype(int)
            df = mark_anomaly(df, error_df)

            # --- ë°ëª¨ë¥¼ ìœ„í•œ ë”ë¯¸ 'prediction' ì»¬ëŸ¼ ì¶”ê°€ ---
            np.random.seed(42)
            df['prediction'] = np.zeros(len(df))
            df.loc[df['is_anomaly'] == 1, 'prediction'] = np.random.uniform(0.6, 0.9, size=df['is_anomaly'].sum())
            df.loc[df['is_anomaly'] == 0, 'prediction'] = np.random.uniform(0.1, 0.4, size=(len(df) - df['is_anomaly'].sum()))
            # --- ë”ë¯¸ 'prediction' ì»¬ëŸ¼ ì¶”ê°€ ë ---

            return df
        
        # ëª¨ë“  ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
        dataframes = [load_one(p) for p in csv_paths]
        df = pd.concat(dataframes, ignore_index=True)
        
        return df
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ì „ì—­ íŒŒë¼ë¯¸í„° (ì´ í˜ì´ì§€ì˜ ë¶„ì„ ë¡œì§ì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
WINDOW_WIDTH  = 3    
SLIDE_STEP    = 1    
SEQ_LEN       = 10   
TRAIN_RATIO   = 0.7
VAL_RATIO     = 0.1

def analyze_anomaly_patterns(df):
    """ì´ìƒ ê°ì§€ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    if df is None or 'is_anomaly' not in df.columns:
        return None
    
    anomaly_df = df[df['is_anomaly'] == 1]
    
    # ì‹œê°„ëŒ€ë³„ ì´ìƒ ë°œìƒ ë¹ˆë„
    anomaly_df['hour'] = pd.to_datetime(anomaly_df['timestamp']).dt.hour
    hourly_pattern = anomaly_df.groupby('hour').size()
    
    # ì´ìƒì¹˜ ë°œìƒ ê°„ê²© ë¶„ì„
    anomaly_df['timestamp'] = pd.to_datetime(anomaly_df['timestamp'])
    anomaly_df = anomaly_df.sort_values('timestamp')
    anomaly_df['time_diff'] = anomaly_df['timestamp'].diff()
    
    return {
        'hourly_pattern': hourly_pattern,
        'time_diff': anomaly_df['time_diff']
    }

def calculate_model_metrics(df):
    """ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    if df is None or 'is_anomaly' not in df.columns or 'prediction' not in df.columns:
        return None
    
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    # ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ì´ì§„ í´ë˜ìŠ¤ë¡œ ë³€í™˜ (ì„ê³„ê°’ 0.5 ì‚¬ìš© ì˜ˆì‹œ)
    # ì‹¤ì œ ëª¨ë¸ì—ì„œëŠ” ì´ ì„ê³„ê°’ì„ ì¡°ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    binary_prediction = (df['prediction'] >= 0.5).astype(int)

    metrics = {
        'precision': precision_score(df['is_anomaly'], binary_prediction),
        'recall': recall_score(df['is_anomaly'], binary_prediction),
        'f1': f1_score(df['is_anomaly'], binary_prediction)
    }
    
    return metrics

def get_total_data_points():
    """ì „ì²´ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    df = load_historical_data()
    if df is None:
        return 0
    return len(df)

def get_anomaly_detection_rate():
    """ì´ìƒ ê°ì§€ìœ¨ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = load_historical_data()
    if df is None or 'is_anomaly' not in df.columns or 'prediction' not in df.columns:
        return 0.0
    
    # ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ì´ì§„ í´ë˜ìŠ¤ë¡œ ë³€í™˜ (ì„ê³„ê°’ 0.5 ì‚¬ìš©)
    binary_prediction = (df['prediction'] >= 0.5).astype(int)
    
    # ì‹¤ì œ ì´ìƒì¹˜ ì¤‘ì—ì„œ ì œëŒ€ë¡œ ê°ì§€ëœ ë¹„ìœ¨
    true_positives = ((df['is_anomaly'] == 1) & (binary_prediction == 1)).sum()
    total_anomalies = (df['is_anomaly'] == 1).sum()
    
    if total_anomalies == 0:
        return 0.0
    
    return (true_positives / total_anomalies) * 100

def get_false_detection_rate():
    """ì˜¤íƒì§€ìœ¨ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = load_historical_data()
    if df is None or 'is_anomaly' not in df.columns or 'prediction' not in df.columns:
        return 0.0
    
    # ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ì´ì§„ í´ë˜ìŠ¤ë¡œ ë³€í™˜ (ì„ê³„ê°’ 0.5 ì‚¬ìš©)
    binary_prediction = (df['prediction'] >= 0.5).astype(int)
    
    # ì •ìƒ ë°ì´í„° ì¤‘ì—ì„œ ì´ìƒìœ¼ë¡œ ì˜ëª» ê°ì§€ëœ ë¹„ìœ¨
    false_positives = ((df['is_anomaly'] == 0) & (binary_prediction == 1)).sum()
    total_normal = (df['is_anomaly'] == 0).sum()
    
    if total_normal == 0:
        return 0.0
    
    return (false_positives / total_normal) * 100

def get_system_uptime():
    """ì‹œìŠ¤í…œ ê°€ë™ë¥ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œìŠ¤í…œ ë¡œê·¸ë‚˜ ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    # í˜„ì¬ëŠ” ë°ëª¨ë¥¼ ìœ„í•´ ê³ ì •ê°’ ë°˜í™˜
    return 99.9

def get_average_response_time():
    """í‰ê·  ì‘ë‹µ ì‹œê°„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œìŠ¤í…œ ë¡œê·¸ë‚˜ ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    # í˜„ì¬ëŠ” ë°ëª¨ë¥¼ ìœ„í•´ ê³ ì •ê°’ ë°˜í™˜
    return 0.12

def main():
    st.title("ğŸ“Š ë°ì´í„° ë¶„ì„")
    
    # ë°ì´í„° ë¡œë“œ
    df = load_historical_data()
    
    if df is None: # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ
        return
    
    # 1. ë°ì´í„° í†µê³„ ì •ë³´
    st.header("ë°ì´í„° í†µê³„ ì •ë³´")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë°ì´í„° í¬ì¸íŠ¸", len(df))
    with col2:
        # 'is_anomaly' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
        if 'is_anomaly' in df.columns:
            st.metric("ì´ìƒì¹˜ ìˆ˜", int(df['is_anomaly'].sum()))
        else:
            st.metric("ì´ìƒì¹˜ ìˆ˜", "N/A")
    with col3:
        if 'is_anomaly' in df.columns:
            st.metric("ì •ìƒ ë°ì´í„° ìˆ˜", int(len(df) - df['is_anomaly'].sum()))
        else:
            st.metric("ì •ìƒ ë°ì´í„° ìˆ˜", "N/A")
   
    # 3. ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„
    st.header("ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„")
    
    if 'is_anomaly' in df.columns and 'timestamp' in df.columns:
        pattern_analysis = analyze_anomaly_patterns(df)
        if pattern_analysis:
            col1, col2 = st.columns(2)
            
            with col1:
                # ì‹œê°„ëŒ€ë³„ ì´ìƒ ë°œìƒ ë¹ˆë„
                fig = px.bar(
                    x=pattern_analysis['hourly_pattern'].index,
                    y=pattern_analysis['hourly_pattern'].values,
                    title='ì‹œê°„ëŒ€ë³„ ì´ìƒ ë°œìƒ ë¹ˆë„',
                    labels={'x': 'ì‹œê°„', 'y': 'ì´ìƒ ë°œìƒ íšŸìˆ˜'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # ì´ìƒì¹˜ ë°œìƒ ê°„ê²© íˆìŠ¤í† ê·¸ë¨
                # timedeltaë¥¼ ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜
                time_diff_minutes = pattern_analysis['time_diff'].dt.total_seconds() / 60
                fig = px.histogram(
                    time_diff_minutes,
                    title='ì´ìƒì¹˜ ë°œìƒ ê°„ê²© ë¶„í¬ (ë¶„)',
                    labels={'value': 'ê°„ê²© (ë¶„)', 'count': 'ë¹ˆë„'}
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ì´ìƒ ê°ì§€ íŒ¨í„´ì„ ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ì´ìƒ ê°ì§€ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ (is_anomaly, timestamp)ì´ ì—†ìŠµë‹ˆë‹¤.")

    
    # 4. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ
    st.header("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
    
    if 'is_anomaly' in df.columns and 'prediction' in df.columns:
        metrics = calculate_model_metrics(df)
        if metrics:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì •ë°€ë„ (Precision)", f"{metrics['precision']:.3f}")
            with col2:
                st.metric("ì¬í˜„ìœ¨ (Recall)", f"{metrics['recall']:.3f}")
            with col3:
                st.metric("F1 ì ìˆ˜", f"{metrics['f1']:.3f}")
            
            # ROC ì»¤ë¸Œ
            from sklearn.metrics import roc_curve, auc
            fpr, tpr, _ = roc_curve(df['is_anomaly'], df['prediction'])
            roc_auc = auc(fpr, tpr)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=fpr,
                y=tpr,
                name=f'ROC ì»¤ë¸Œ (AUC = {roc_auc:.3f})'
            ))
            fig.add_trace(go.Scatter(
                x=[0, 1],
                y=[0, 1],
                name='ë¬´ì‘ìœ„ ì˜ˆì¸¡',
                line=dict(dash='dash')
            ))
            
            fig.update_layout(
                title='ROC ì»¤ë¸Œ',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                xaxis=dict(range=[0, 1], constrain='range'), # ROC ì»¤ë¸Œ ë²”ìœ„ ê³ ì •
                yaxis=dict(range=[0, 1], scaleanchor='x', scaleratio=1, constrain='range') # ROC ì»¤ë¸Œ ë²”ìœ„ ê³ ì •
            )
            
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ (is_anomaly, prediction)ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
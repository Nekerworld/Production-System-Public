# ìˆ˜ë™ ê²€ì‚¬ í˜ì´ì§€
# ì‚¬ìš©ìê°€ ì§ì ‘ ì „ë¥˜ì™€ ì˜¨ë„ ê°’ì„ ì…ë ¥í•˜ì—¬ ê²€ì‚¬
# ì…ë ¥ëœ ë°ì´í„°ì— ëŒ€í•œ ì •ìƒ/ì´ìƒ í™•ë¥  ê³„ì‚°
# ì…ë ¥ ë°ì´í„°ì˜ ì‹œê°í™”
# ê²€ì‚¬ ê²°ê³¼ íˆìŠ¤í† ë¦¬

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import logging
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
import joblib
from typing import List, Tuple, Optional, Dict, Any, Union
from dataclasses import dataclass
from pathlib import Path
from glob import glob
from collections import deque

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜
SEQ_LEN = 10  # ì‹œí€€ìŠ¤ ê¸¸ì´
DATA_DIR = os.path.join('data', 'ì¥ë¹„ì´ìƒ ì¡°ê¸°íƒì§€', '5ê³µì •_180sec')  # ë°ì´í„° ë””ë ‰í† ë¦¬

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìˆ˜ë™ ê²€ì‚¬",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

@dataclass
class PredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    anomaly_probability: float
    is_anomaly: bool
    last_sequence: Dict[str, Any]
    prediction_history: Dict[str, List[Any]]
    visualization: go.Figure

class AnomalyPredictor:
    """ì´ìƒì¹˜ ì˜ˆì¸¡ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, model_dir: Union[str, Path] = 'models'):
        """
        Args:
            model_dir (Union[str, Path]): ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.model_dir = Path(model_dir)
        self.model: Optional[keras.Model] = None
        self.scaler: Optional[StandardScaler] = None
        self.seq_len = SEQ_LEN
        self.threshold = 0.5
        self.historical_data: Optional[pd.DataFrame] = None
        self.window_buffer: deque[Dict[str, Any]] = deque(maxlen=SEQ_LEN)
        
    def load_historical_data(self) -> None:
        """ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # ì—ëŸ¬ ë°ì´í„° ë¡œë“œ
            error_df = pd.read_csv(os.path.join(DATA_DIR, 'Error Lot list.csv'))
            
            def mark_anomaly(df, err):
                df['is_anomaly'] = 0
                for _, row in err.iterrows():
                    date = str(row.iloc[0]).strip()
                    procs = set(row.iloc[1:].dropna().astype(int))
                    if procs:
                        mask = (df['Date'] == date) & (df['Process'].isin(procs))
                        df.loc[mask, 'is_anomaly'] = 1
                return df
            
            def load_one(path):
                df = pd.read_csv(path)
                df['Time'] = (df['Time'].str.replace('ì˜¤ì „', 'AM')
                                      .str.replace('ì˜¤í›„', 'PM'))
                df['Time'] = pd.to_datetime(df['Time'], format='%p %I:%M:%S.%f').dt.strftime('%H:%M:%S.%f')
                df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])
                df['Index'] = df['Index'].astype(int)
                df = mark_anomaly(df, error_df)
                return df
            
            # CSV íŒŒì¼ ê²½ë¡œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            csv_paths = [p for p in glob(os.path.join(DATA_DIR, '*.csv')) if
                        'Error Lot list' not in os.path.basename(p)]
            
            # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë¡œë“œ ë° ë³‘í•©
            dataframes = [load_one(p) for p in csv_paths]
            self.historical_data = pd.concat(dataframes, ignore_index=True)
            self.historical_data = self.historical_data.sort_values('datetime')  # ì‹œê°„ìˆœ ì •ë ¬
            
            logger.info("ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
        
    def load_models(self) -> None:
        """ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # ëª¨ë¸ ë¡œë“œ
            model_path = self.model_dir / 'final_model.keras'
            if not model_path.exists():
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            self.model = keras.models.load_model(model_path)
            logger.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            scaler_files = list(self.model_dir.glob('global_scaler.pkl'))
            if not scaler_files:
                raise FileNotFoundError("ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            self.scaler = joblib.load(scaler_files[0])
            logger.info("ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            self.load_historical_data()
            
        except Exception as e:
            logger.error(f"ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def prepare_single_input(self, current: float, temp: float) -> pd.DataFrame:
        """
        ë‹¨ì¼ ì…ë ¥ê°’ì„ ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            current (float): ì „ë¥˜ ê°’
            temp (float): ì˜¨ë„ ê°’
            
        Returns:
            pd.DataFrame: ì‹œí€€ìŠ¤ ë°ì´í„°
        """
        try:
            if self.historical_data is None:
                raise ValueError("ê¸°ì¡´ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
            current_time = datetime.now()
            
            # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸°
            ref_data = self.historical_data[['Current', 'Temp']].values
            input_data = np.array([[current, temp]])
            
            # ìœ ì‚¬ë„ ê³„ì‚° (ìœ í´ë¦¬ë“œ ê±°ë¦¬)
            distances = np.linalg.norm(ref_data - input_data, axis=1)
            most_similar_idx = np.argmin(distances)
            
            # ê°€ì¥ ìœ ì‚¬í•œ ì‹œí€€ìŠ¤ì˜ ì´ì „ ë°ì´í„° ì‚¬ìš©
            start_idx = max(0, most_similar_idx - self.seq_len + 1)
            sequence = self.historical_data.iloc[start_idx:start_idx + self.seq_len - 1].copy()
            
            # ë§ˆì§€ë§‰ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ê°€
            new_point = pd.DataFrame({
                'Date': [current_time.strftime('%Y-%m-%d')],
                'Time': [current_time.strftime('%p %I:%M:%S.%f')],
                'Current': [current],
                'Temp': [temp],
                'Process': [1],
                'datetime': [current_time],
                'Index': [sequence['Index'].iloc[-1] + 1],
                'is_anomaly': [0]
            })
            
            sequence = pd.concat([sequence, new_point], ignore_index=True)
            return sequence
            
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def prepare_sequence(self, data: pd.DataFrame, scaler: StandardScaler) -> np.ndarray:
        """
        ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì…ë ¥ ë°ì´í„°
            scaler (StandardScaler): ìŠ¤ì¼€ì¼ëŸ¬ ê°ì²´
            
        Returns:
            np.ndarray: ì‹œí€€ìŠ¤ ë°ì´í„°
        """
        try:
            if len(data) < self.seq_len:
                raise ValueError(f"ë°ì´í„° ê¸¸ì´ê°€ {self.seq_len}ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.")
            
            features = data[['Temp', 'Current']].copy()
            scaled_data = pd.DataFrame(
                scaler.transform(features),
                columns=features.columns,
                index=features.index
            )
            
            X = np.array([
                scaled_data.iloc[i:i+self.seq_len].values
                for i in range(len(data) - self.seq_len + 1)
            ])
            return X
            
        except Exception as e:
            logger.error(f"ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def format_prediction_result(self, 
                               predictions: np.ndarray, 
                               data: pd.DataFrame,
                               last_probability: float) -> PredictionResult:
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        Args:
            predictions (np.ndarray): ì˜ˆì¸¡ í™•ë¥  ë°°ì—´
            data (pd.DataFrame): ì›ë³¸ ë°ì´í„°
            last_probability (float): ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ 
            
        Returns:
            PredictionResult: í¬ë§·íŒ…ëœ ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            last_sequence = data.iloc[-self.seq_len:]
            start_time = pd.to_datetime(last_sequence['datetime'].iloc[0])
            end_time = pd.to_datetime(last_sequence['datetime'].iloc[-1])
            
            # ë‹¨ì¼ ê·¸ë˜í”„ë¡œ ë³€ê²½
            fig = go.Figure()
            
            if self.historical_data is not None:
                # ì •ìƒ ë° ì´ìƒ ë°ì´í„° ë¶„ë¥˜
                normal_data = self.historical_data[self.historical_data['is_anomaly'] == 0]
                anomaly_data = self.historical_data[self.historical_data['is_anomaly'] == 1]
                
                # ê° ë°ì´í„°ì—ì„œ 1%ë§Œ ìƒ˜í”Œë§
                normal_sample = normal_data.sample(frac=0.01, random_state=42) if not normal_data.empty else pd.DataFrame()
                anomaly_sample = anomaly_data.sample(frac=0.01, random_state=42) if not anomaly_data.empty else pd.DataFrame()
                
                # ì •ìƒ ë°ì´í„° ì‹œê°í™”
                if not normal_sample.empty:
                    fig.add_trace(
                        go.Scatter(
                            x=normal_sample['Temp'],
                            y=normal_sample['Current'],
                            mode='markers',
                            name='Normal Data',
                            marker=dict(color='blue', size=5, opacity=0.6)
                        )
                    )
                
                # ì´ìƒ ë°ì´í„° ì‹œê°í™”
                if not anomaly_sample.empty:
                    fig.add_trace(
                        go.Scatter(
                            x=anomaly_sample['Temp'],
                            y=anomaly_sample['Current'],
                            mode='markers',
                            name='Anomaly Data',
                            marker=dict(color='red', size=7, symbol='x')
                        )
                    )

            # í˜„ì¬ ì…ë ¥ëœ ë°ì´í„°ë¥¼ ëˆˆì— ë„ëŠ” ì ìœ¼ë¡œ ì¶”ê°€
            current_temp = data['Temp'].iloc[-1]
            current_current = data['Current'].iloc[-1]
            
            fig.add_trace(
                go.Scatter(
                    x=[current_temp],
                    y=[current_current],
                    mode='markers',
                    name='Input Point',
                    marker=dict(color='orange', size=12, symbol='star')
                )
            )

            fig.update_layout(
                height=600,
                showlegend=True,
                title_text="Current vs. Temperature Anomaly Detection",
                xaxis_title="Temperature",
                yaxis_title="Current"
            )
            
            return PredictionResult(
                timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                anomaly_probability=float(last_probability),
                is_anomaly=bool(last_probability >= self.threshold),
                last_sequence={
                    'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'end_time': end_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'avg_temperature': float(last_sequence['Temp'].mean()),
                    'avg_current': float(last_sequence['Current'].mean()),
                    'process_id': int(last_sequence['Process'].iloc[-1])
                },
                prediction_history={
                    'timestamps': [start_time.strftime('%Y-%m-%d %H:%M:%S')],
                    'probabilities': [float(p[0]) for p in predictions]
                },
                visualization=fig
            )
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {str(e)}")
            raise
    
    def predict(self, data: pd.DataFrame) -> Tuple[np.ndarray, float, PredictionResult]:
        """
        ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì´ìƒì¹˜ í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì˜ˆì¸¡í•  ë°ì´í„°
            
        Returns:
            Tuple[np.ndarray, float, PredictionResult]: 
                (ì „ì²´ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ , ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ , í¬ë§·íŒ…ëœ ê²°ê³¼)
        """
        try:
            if self.model is None or self.scaler is None:
                self.load_models()
            
            if 'datetime' not in data.columns:
                data['Time'] = (data['Time'].str.replace('ì˜¤ì „', 'AM')
                                          .str.replace('ì˜¤í›„', 'PM'))
                data['Time'] = pd.to_datetime(data['Time'], format='%p %I:%M:%S.%f').dt.strftime('%H:%M:%S.%f')
                data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])
            
            X = self.prepare_sequence(data, self.scaler)
            predictions = self.model.predict(X, verbose=0)
            last_probability = predictions[-1][0]
            
            formatted_result = self.format_prediction_result(predictions, data, last_probability)
            
            logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì´ìƒì¹˜ í™•ë¥  = {last_probability*100:.2f}%")
            return predictions, last_probability, formatted_result
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            raise

@st.cache_resource
def get_predictor() -> Optional[AnomalyPredictor]:
    """AnomalyPredictor ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìºì‹±í•˜ì—¬ ëª¨ë¸ ë¡œë“œë¥¼ í•œ ë²ˆë§Œ ìˆ˜í–‰"""
    predictor = AnomalyPredictor()
    try:
        predictor.load_models()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}. 'models' ë””ë ‰í† ë¦¬ì— final_model.kerasì™€ global_scaler.pkl íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    return predictor

def main() -> None:
    st.title("ìˆ˜ë™ ê²€ì‚¬ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")

    predictor = get_predictor()
    if predictor is None:
        return

    st.subheader("ìƒˆë¡œìš´ ë°ì´í„° ì…ë ¥")
    col1, col2 = st.columns(2)

    with col1:
        current_input = st.number_input("ì „ë¥˜ ê°’ (Current)", min_value=0.0, value=1.6, step=0.01)
    with col2:
        temp_input = st.number_input("ì˜¨ë„ ê°’ (Temperature)", min_value=0.0, value=70.0, step=0.01)

    if st.button("ì´ìƒì¹˜ ê²€ì‚¬ ì‹¤í–‰"):
        try:
            # ë‹¨ì¼ ì…ë ¥ê°’ìœ¼ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
            sequence_data = predictor.prepare_single_input(current_input, temp_input)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            _, last_prob, result = predictor.predict(sequence_data)
            
            st.subheader("ê²€ì‚¬ ê²°ê³¼")
            col_res1, col_res2 = st.columns(2)
            with col_res1:
                st.metric("ì´ìƒì¹˜ í™•ë¥ ", f"{result.anomaly_probability*100:.2f}%")
            with col2:
                status_text = "ì´ìƒ ê°ì§€" if result.is_anomaly else "ì •ìƒ"
                status_color = "red" if result.is_anomaly else "green"
                st.markdown(
                    f"<div style='font-size:20px; color:{status_color}; font-weight:bold;'>ìƒíƒœ: {status_text}</div>",
                    unsafe_allow_html=True
                )
            
            st.info(f"**ì„ê³„ê°’:** {predictor.threshold:.2f}, **ì‹ ë¢°ë„:** {'ë†’ìŒ' if result.anomaly_probability > 0.8 else 'ì¤‘ê°„' if result.anomaly_probability > 0.5 else 'ë‚®ìŒ'}")

            st.subheader("ì…ë ¥ ë°ì´í„° ì‹œê°í™”")
            st.plotly_chart(result.visualization, use_container_width=True)
            
            if 'manual_check_history' not in st.session_state:
                st.session_state.manual_check_history = []
            
            st.session_state.manual_check_history.append({
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'current': current_input,
                'temperature': temp_input,
                'probability': result.anomaly_probability * 100,
                'status': status_text
            })
            
            st.subheader("ê²€ì‚¬ ê²°ê³¼ íˆìŠ¤í† ë¦¬")
            display_history = pd.DataFrame(st.session_state.manual_check_history).tail(10)
            if not display_history.empty:
                st.dataframe(display_history.set_index('timestamp'))
            else:
                st.info("ì•„ì§ ê²€ì‚¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    st.markdown("---")
    st.markdown("**ì°¸ê³ :** ì…ë ¥ëœ ê°’ì€ ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ íŒ¨í„´ì„ ì°¾ì•„ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()